---
title: "Análise exploratória de aprendizagem de paradigmas"
output:
  html_document:
    df_print: paged
---

```{r setup, message=FALSE, warning=FALSE}
library(readr)
library(stringr)
library(dplyr)
library(plotly)
```

```{r, message=FALSE}
# Leitura dos dados
dados_plp <- read_csv("../data/plp_modificada.csv") %>% 
  rename(cod_atividade = atividade)
atv_paradigmas <- read_csv("../data/atv_paradigms.csv") %>% 
  rename(cod_atividade = codigo_atv)
atv_aluno_duracao  <- read_csv("../data/atv_aluno_duracao.csv")
```

```{r, message=FALSE}
# Tratamento dos dados
# Filtrar os horários de submissões para apenas dias dos laboratórios
dados_plp <- dados_plp %>%
  filter(str_sub(horario_submissao, start = 12, end = 13) >= 18) %>%
  filter(str_sub(horario_submissao, start = 12, end = 13) < 21) %>%
  filter(str_sub(horario_submissao, start = 0, end = 10) %in% c(
    "2017-06-27", "2017-10-27", "2017-11-24", "2017-12-01", "2018-02-09", "2018-05-11", "2018-06-15", "2018-06-22", "2018-07-13", "2018-07-20", "2018-09-14", "2018-10-05", "2018-10-19", "2018-11-09", "2018-11-23", "2019-04-05", "2019-05-03", "2019-05-10", "2019-06-07", "2019-06-21")) %>%
  filter(!aluno %in% (
    "everton@computacao.ufcg.edu.br"
  ))

#Classificar testes como corretos
dados_plp["correta"] <- !str_detect(dados_plp$testes, pattern = "f+")
```

```{r, message=FALSE}
submissoes_atv <- dados_plp %>% group_by(cod_atividade) %>% count(cod_atividade)

teste_attv <- dados_plp %>%
  group_by(cod_atividade) %>% count(correta)

acertos_atividade <- teste_attv %>%
  filter(correta == TRUE)
  
erros_atividade <- teste_attv %>%
  filter(correta == FALSE) 

dados_atividade <- merge(x=acertos_atividade, y=erros_atividade[,c("cod_atividade", "n")], by = "cod_atividade", suffix = c("_acertos", "_erros"), all.x = TRUE)
dados_atividade <- merge(x=dados_atividade, y=submissoes_atv, by = "cod_atividade", all.x = TRUE) %>% 
  mutate(coeficiente = n_acertos/n) %>% 
  select(-correta)

atividades_paradigmas <- inner_join(dados_atividade, atv_paradigmas, by = "cod_atividade")

```
### Sumário dos dados

```{r}
alunos20172 <- atv_aluno_duracao %>% filter(periodo=="2017.2") %>% group_by(aluno) %>% summarise(n())
alunos20181 <- atv_aluno_duracao %>% filter(periodo=="2018.1") %>% group_by(aluno) %>% summarise(n())
alunos20182 <- atv_aluno_duracao %>% filter(periodo=="2018.2") %>% group_by(aluno) %>% summarise(n())
alunos20191 <- atv_aluno_duracao %>% filter(periodo=="2019.1") %>% group_by(aluno) %>% summarise(n())

tarefas20172 <- atividades_paradigmas %>% filter(periodo=="2017.2")
tarefas20181 <- atividades_paradigmas %>% filter(periodo=="2018.1")
tarefas20182 <- atividades_paradigmas %>% filter(periodo=="2018.2")
tarefas20191 <- atividades_paradigmas %>% filter(periodo=="2019.1")

df <- data.frame(
  "período" = c("2017.2", "2018.1", "2018.2", "2019.1"),
  "n_alunos"= c(nrow(alunos20172), nrow(alunos20181), nrow(alunos20182), nrow(alunos20191)),
  "n_atividades"= c(13, 14, 15, 15),
  "n_submissoes"=c(sum(tarefas20172$n), sum(tarefas20181$n), sum(tarefas20182$n), sum(tarefas20191$n)),
  "n_acertos"=c(sum(tarefas20172$n_acertos), sum(tarefas20181$n_acertos), sum(tarefas20182$n_acertos), sum(tarefas20191$n_acertos)),
  "n_erros"=c(sum(tarefas20172$n_erros), sum(tarefas20181$n_erros), sum(tarefas20182$n_erros), sum(tarefas20191$n_erros))
  )
df

```

```{r}
imp <- atividades_paradigmas %>% filter(paradigma=="Procedural")
func <- atividades_paradigmas %>% filter(paradigma=="Funcional")
log <- atividades_paradigmas %>% filter(paradigma=="Lógico")

par <- data.frame(
  "paradigma" = c("Imperativo", "Funcional", "Lógico"),
  "n_atividades"= c(nrow(imp), nrow(func), nrow(log)),
  "n_submissoes"=c(sum(imp$n), sum(func$n), sum(log$n)),
  "n_acertos"=c(sum(imp$n_acertos), sum(func$n_acertos), sum(log$n_acertos)),
  "n_erros"=c(sum(imp$n_erros), sum(func$n_erros), sum(log$n_erros))
  )
par

```




### 1. Relação entre atividades e paradigmas

Tendo em vista que todas as atividades estão relacionados aos paradigmas, podemos ver se o comportamento está relacionado paradigma.

Para uma melhor visualização será utilizado um gráfico dispersão, o qual no eixo x apresenta cada atividade e y a métrica a ser analisada(quantidade de acertos ou erros e o coeficiente), utilizamos as cores dos pontos para representar qual paradigma exercitado pela atividade.

### 1.1 Quantidade de submissões

```{r}
#TODO: Adicionar legendas e títulos
plot_ly(x = atividades_paradigmas$n,
        type = "histogram",
        name="Submissões x Acertos")

#TODO: REMOVER A LEGENDA DE ATIVIDADES.
atividades_paradigmas %>% 
  ggplot(aes(x = cod_atividade,
             y = n,
             color = paradigma)) +
  geom_jitter() +
  labs(title = "Distribuição de submissões por atividade",
       x = "Atividade",
       y= "Quantidade de submissões")
```

Com o histograma conseguimos uma visualização que indica a quantidade de atividades (eixo y) que apresentaram o valor x de submissões. Dessa forma, é possível definir intervalos e comportamentos.

* Atípico 1: abaixo de 50 submissões
* Típico: 50 à 119 submissões
* Atípico 2: acima de 119 submissões - Existem 9 casos

O segundo gráfico proporciona a visualização com o paradigma, dessa forma podemos determinar quais os paradigmas das questões para as classes:

#### Atípicas do tipo 1:
* 3 casos, com 0 submissões. (Laboratório PrologA no período 2017.2)

#### Atípicas do tipo 2:
* 1 questão de haskell
(PtgBJ0pQO	61	206	267	0.2284644	Haskell	2017.2	HaskellA)
* 4 questões de prolog
(
QEDoVk8tE	69	133	202	0.3415842	Prolog	2017.2	PrologB
StYJaP03k	75	97	172	0.4360465	Prolog	2018.2	PrologA
RuvTx3uKG	72	80	152	0.4736842	Prolog	2018.2	PrologB
RYIhBbemO2	82	48	130	0.6307692	Prolog	2018.1	PrologB
)
* 4 questões de C
(
U0VYCbVQW	42	121	163	0.2576687	C	2018.1	C
MgUDVyxCy	53	73	126	0.4206349	C	2018.2	C
UqBk7Iogi	41	84	125	0.3280000	C	2018.2	C
U61k02zZY	53	68	121	0.4380165	C	2017.2	C
)

### 1.2 Quantidade de acertos

```{r}
plot_ly(x = atividades_paradigmas$n_acertos,
        type = "histogram",
        name="Atividade x Acertos")

atividades_paradigmas %>% 
  ggplot(aes(x = cod_atividade,
             y = n_acertos,
             color = paradigma)) +
  geom_jitter() +
  labs(title = "Distribuição de acertos por atividade",
       x = "Atividade",
       y= "Quantidade de acertos")

```

### 1.3 Coeficientes
```{r}
plot_ly(x = atividades_paradigmas$coeficiente,
        type = "histogram",
        name="Coeficiente x Atividade")

atividades_paradigmas %>% 
  ggplot(aes(x = cod_atividade,
             y = coeficiente,
             color = paradigma)) +
  geom_jitter() +
  labs(title = "Distribuição de coeficiente por atividade",
       x = "Atividade",
       y= "Coeficiente")

```

ORDENAR POR SUBMISSAO
(não é possível ordernar por submissão, já que aqui ele verifica informações sobre a atividade e não por cada submissão em específico).

Com o histograma conseguimos uma visualização que indica a quantidade de atividades (eixo y) que apresentaram o valor x de coeficiente. Dessa forma, é possível definir intervalos e comportamentos.

* Atípico 1: abaixo de 0.35 - Existem 4 casos (7 com os labs com 0 submissões)
* Típico: 0.35 entre 0.85
* Atípico 2: acima de 0.85 - Existem 4 casos

O segundo gráfico proporciona a visualização com o paradigma, dessa forma podemos determinar quais os paradigmas das questões para as classes:

#### Atípicas do tipo 1:
* 5 casos, com 0 submissões. (Laboratório PrologA no período 2017.2)
(
PvlPfDNp2	11	94	105	0.1047619	Prolog	2018.1	PrologB
PtgBJ0pQO	61	206	267	0.2284644	Haskell	2017.2	HaskellA
U0VYCbVQW	42	121	163	0.2576687	C	2018.1	C
UqBk7Iogi	41	84	125	0.3280000	C	2018.2	C
QEDoVk8tE	69	133	202	0.3415842	Prolog	2017.2	PrologB
)

#### Atípicas do tipo 2:
* 4 questões de haskell
(
SWdTuSnEO	35	1	36	0.9722222	Haskell	2018.2	HaskellA
PYHdqJCqm	43	3	46	0.9347826	Haskell	2018.1	HaskellA
Rby1sBQg4	40	3	43	0.9302326	Haskell	2019.1	HaskellA
PwBB0JTiS	71	7	78	0.9102564	Haskell	2018.2	HaskellB
)

Para o caso das atípicas, o coeficiente foi elevado porque a quantidade total de submissões são baixas.


#### Comparativos de acertos e erros

O gráfico a seguir nos faz ter um comparativo de acertos e erros por questão, percebemos que no geral a quantidade de acertos é maior do que a de erros, em alguns casos específicos a taxa de erro é bastante significativa.

```{r}
p <- ggplot(atividades_paradigmas, aes(x=x) ) +
  # Top
  geom_col( aes(x = cod_atividade, y = (n_acertos)), fill="#69b3a2" ) +
  #geom_label( aes(x=5, y=85, label="nº de acertos"), color="#69b3a2") +
  # Bottom
  geom_col( aes(x = cod_atividade, y = -(n_erros)), fill= "#404080") +
  #geom_label( aes(x=5, y=-200, label="nº de erros"), color="#404080") +
  xlab("Atividades")

ggplotly(p)
```


## Laboratório

### 1.1 Quantidade de submissões por laboratório
```{r}
atividades_paradigmas %>% 
  group_by(laboratorio) %>% 
  ggplot(aes(x = laboratorio,
             y = n)) +
  ylab("Submissões") +
  ggtitle("Submissões por Laboratório", subtitle = waiver()) +
  geom_col()
```

O laboratório com maior quantidade de submissões é o de Prolog Básico, seguido pelo laboratório de C.


### 1.2 Quantidade de corretas por laboratório
```{r}
atividades_paradigmas %>% 
  group_by(laboratorio) %>% 
  ggplot(aes(x = laboratorio,
             y = n_acertos)) +
  ylab("Acertos") +
  ggtitle("Acertos por Laboratório", subtitle = waiver()) +
  geom_col()
```


#### Boxplot laboratório
```{r}
p <- atividades_paradigmas %>% 
    group_by(laboratorio) %>% 
    ggplot(aes(x = laboratorio,
               y = n)) +
    geom_boxplot() +
    ggtitle("Boxplot com submissao por laboratorio", subtitle = waiver()) +
    geom_point()

ggplotly(p)

p <- atividades_paradigmas %>% 
  group_by(laboratorio) %>% 
  ggplot(aes(x = laboratorio,
             y = coeficiente)) +
  geom_boxplot() +
  ggtitle("Boxplot com coeficiente por laboratorio", subtitle = waiver()) +
  geom_point()

ggplotly(p)

lab <-atividades_paradigmas %>% 
  group_by(laboratorio) 
```

### 1.3 Coeficiente por laboratório
```{r}
atividades_paradigmas %>% 
  group_by(laboratorio) %>% 
  ggplot(aes(x = laboratorio,
             y = coeficiente,
             color = laboratorio)) +
  geom_jitter() +
  labs(title = "Distribuição de coeficiente por laboratório",
       x = "Laboratório",
       y= "Coeficiente")

```


Em relação ao laboratório podemos ver que existe uma maior quantidade de submissões para os labs com maior quantidade possuem um coeficiente baixo, podemos entender que para esses laboratórios são necessárias várias submissões para conseguir resultados corretos.

OBS: C possue bastante submissões, provavelmente por ser o primeiro laboratório estão se adaptando ao ambiente, como também é um paradigma com apenas 1 laboratório então, deveria ter menos submissões ?


### Teste estatístico

```{r}

kruskal.test(atividades_paradigmas$n, as.factor(atividades_paradigmas$laboratorio))

c <- atividades_paradigmas %>%
                filter(laboratorio %in% c("C"))
haskellba <- atividades_paradigmas %>%
                filter(laboratorio %in% c("HaskellBasico"))
haskellav <- atividades_paradigmas %>%
                filter(laboratorio %in% c("HaskellAvancado"))
prologba <- atividades_paradigmas %>%
                filter(laboratorio %in% c("PrologBasico"))
prologav <- atividades_paradigmas %>%
                filter(laboratorio %in% c("PrologAvancado"))

#wilcox.test(c$n, haskellav$n)
#wilcox.test(c$n, haskellba$n)
#wilcox.test(c$n, prologav$n)
#wilcox.test(c$n, prologba$n)


#wilcox.test(haskellav$n, prologav$n)
#wilcox.test(haskellba$n, prologav$n)
#wilcox.test(prologba$n, prologav$n)

#wilcox.test(haskellav$n, prologba$n)
#wilcox.test(haskellba$n, prologba$n)

#wilcox.test(haskellav$n, haskellba$n)
```


coeficientes


```{r}

atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 'C'] <- 0
atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 'HaskellBasico'] <- 1
atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 'HaskellAvancado'] <- 2
atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 'PrologBasico'] <- 3
atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 'PrologAvancado'] <- 4

t.test(atividades_paradigmas$coeficiente, as.numeric(atividades_paradigmas$laboratorio))

atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 0] <- 'C'
atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 1] <- 'HaskellBasico'
atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 2] <- 'HaskellAvancado'
atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 3] <- 'PrologBasico'
atividades_paradigmas$laboratorio[atividades_paradigmas$laboratorio == 4] <- 'PrologAvancado'

t.test(c$coeficiente, haskellav$coeficiente)
t.test(c$coeficiente, haskellba$coeficiente)
t.test(c$coeficiente, prologav$coeficiente)
t.test(c$coeficiente, prologba$coeficiente)


t.test(haskellav$coeficiente, prologav$coeficiente)
t.test(haskellba$coeficiente, prologav$coeficiente)
t.test(prologba$coeficiente, prologav$coeficiente)

t.test(haskellav$coeficiente, prologba$coeficiente)
t.test(haskellba$coeficiente, prologba$coeficiente)

t.test(haskellav$coeficiente, haskellba$coeficiente)
```


## Paradigma

### 1.1 Quantidade de submissões por paradigma
```{r}
atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 'Procedural'] <- 'Imperativo'
atividades_paradigmas %>% 
  group_by(paradigma) %>% 
  ggplot(aes(x = paradigma,
             y = n)) +
  ylab("Submissões") +
  ggtitle("Submissões por paradigma", subtitle = waiver()) +
  geom_col()



sub <- atividades_paradigmas %>% 
  group_by(paradigma) %>% 
  summarise(submissao = sum(n))
sub$fraction = sub$submissao / sum(sub$submissao)
sub$ymax = cumsum(sub$fraction)
sub$ymin = c(0, head(sub$ymax, n=-1))


sub
ggplot(sub, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=paradigma)) +
     geom_rect() +
     coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
     xlim(c(2, 4)) # Try to remove that to see how to make a pie chart
```

O paradigma com maior quantidade de submissões é o de Prolog. 


### 1.2 Quantidade de acertos por paradigma
```{r}
atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 'Procedural'] <- 'Imperativo'

atividades_paradigmas %>% 
  group_by(paradigma) %>% 
  ggplot(aes(x = paradigma,
             y = n_acertos)) +
  ylab("Numero de acertos") +
  ggtitle("Acertos por paradigma", subtitle = waiver()) +
  geom_col()
```

### 1.3 Coeficiente por paradigma
```{r}
atividades_paradigmas %>% 
  group_by(paradigma) %>% 
  ggplot(aes(x = paradigma,
             y = coeficiente)) +
  ylab("Coeficiente") +
  ggtitle("Coeficiente por paradigma", subtitle = waiver()) +
  geom_col()
```

#### Boxplot paradigma
```{r}
atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 'Procedural'] <- 'Imperativo'

p <- atividades_paradigmas %>% 
  ggplot(aes(x = paradigma,
             y = n)) +
  geom_boxplot() +
  ggtitle("Boxplot com submissao por paradigma", subtitle = waiver()) +
  geom_point()
  #geom_jitter()

ggplotly(p)

p <- atividades_paradigmas %>% 
  ggplot(aes(x = paradigma,
             y = coeficiente)) +
  geom_boxplot() +
  ggtitle("Boxplot com coeficiente por paradigma", subtitle = waiver()) +
  geom_point()
  #geom_jitter()

ggplotly(p)
```


Mesmo sendo o paradimga Prolog com o maior número de submissões.

### Verificar normalidade dos dados

ho: dados possuem distribuição normal
ha: dados não possuem distribuição normal

"Dessa forma, quando o teste resulta em um “p” menor que 0,05, isto quer dizer que os dados não possuem distribuição normal. Da mesma forma, valores de “p” maiores que 0,05 indicam que os dados apresentam a distribuição normal."

```{r}
shapiro.test(atividades_paradigmas$n)
shapiro.test(atividades_paradigmas$n_acertos)
shapiro.test(atividades_paradigmas$coeficiente)
```

Observando a métrica de shapiro, podemos determinar que apenas os dados atividade x n_acertos são normalizados, sendo assim poderemos aplicar os testes.

### Ttest

Com o resultado do teste de shapiro podemos definir que o coeficiente apresenta distribuição normal dos dados.

"O teste t de Student ou somente teste t é um teste de hipótese que usa conceitos estatísticos para rejeitar ou não uma hipótese nula quando a estatística de teste t segue uma distribuição t de Student.

Essa premissa é normalmente usada quando a estatística de teste, na verdade, segue uma distribuição normal, mas a variância da população sigma2 é desconhecida. Nesse caso, é usada a variância amostral s^2 e, com esse ajuste, a estatística de teste passa a seguir uma distribuição t de Student."


h0: 



```{r}
atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 'Procedural'] <- 0
atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 'Funcional'] <- 1
atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 'Lógico'] <- 2

t.test(atividades_paradigmas$coeficiente, as.numeric(atividades_paradigmas$paradigma))

atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 0] <- 'Procedural'
atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 1] <- 'Funcional'
atividades_paradigmas$paradigma[atividades_paradigmas$paradigma == 2] <- 'Lógico'
```





### Teste Kruskal-Wallis

"É um teste não paramétrico utilizado para comparar três ou mais populações. Ele é usado para testar a hipótese nula de que todas as populações possuem funções de distribuição iguais contra a hipótese alternativa de que ao menos duas das populações possuem funções de distribuição diferentes.

1. Estabelecemos as hipótese
  
2. Ordenamos de forma crescente de magnitude os valores deste novo conjunto de dados e associamos a cada valor seu posto correspondente, tendo cada posto o mesmo sinal do valor que este representa.

3. Calculamos o valor da estatística H. Em seguida, fixamos o nível de significância α.

4. Encontramos os valores críticos referentes ao nível de significância fixado. Neste caso, calculamos os valores Qα  de modo que P[H > Qα ] = α (sob $ H_0 $).

5. Se Hobs > Qα rejeitamos a hipótese nula de que as amostras provém de populações igualmente distribuídas.

http://www.portalaction.com.br/tecnicas-nao-parametricas/teste-de-kruskal-wallis

Os dados não apresentam distribuição normal, para avaliá-los utilizei o Teste de Kruskal-Wallis 

* Ho = Não há diferença na função de distribuição das amostras
* H1 = Não são todas iguais

```{r}
kruskal.test(atividades_paradigmas$n, as.factor(atividades_paradigmas$paradigma))
```


Tendo em vista que todos os p-valores foram inferiores à 0.5 não podemos recusar a hipótese 0, e temos que os dados possuem diferença na função de distribuição, uma vez analisada esse ponto, vamos verificar se entre os paradigmas os mesmos possuem funções de distribuição diferentes.


### Par a par

```{r}
procedural <- atividades_paradigmas %>%
                filter(paradigma %in% c("Imperativo"))
logico <- atividades_paradigmas %>%
                filter(paradigma %in% c("Lógico"))
funcional <- atividades_paradigmas %>%
                filter(paradigma %in% c("Funcional"))
```


Em estatística o teste U de Mann-Whitney (também conhecido por teste da soma dos postos de Wilcoxon, teste de Wilcoxon-Mann-Whitney ou teste de Mann-Whitney)[1] É um teste não paramétrico aplicado para duas amostras independentes. É de fato a versão da rotina de teste não-paramétrico de t de Student.

Primeiro, notamos que o valor-p é um pouco menor que 0,05. Com base nesse resultado, podemos concluir que as medianas dessas duas distribuições diferem. A hipótese alternativa é declarada como "a verdadeira mudança de local não é igual a 0". Essa é outra maneira de dizer "a distribuição de uma população é deslocada para a esquerda ou direita da outra", o que implica medianas diferentes.




#### Procedural e Funcional


```{r}
t.test(procedural$coeficiente, funcional$coeficiente)

#### Procedural e Lógico
t.test(procedural$coeficiente, logico$coeficiente)

#### Funcional e Lógico
t.test(funcional$coeficiente, logico$coeficiente)
```


Em todos os casos o p-valor para a análise de coeficiente foi inferior a 0.05 sendo assim podemos rejeitar a Ho de que possuem a mesma mediana.


###  Tempo em milissegundos por atividades por alunos

```{r}
atv_aluno_duracao$paradigma[atv_aluno_duracao$paradigma == 'Procedural'] <- 'Imperativo'

atv_aluno_duracao %>% 
  ggplot(aes(x = cod_atividade,
             y = duracao,
             color = paradigma)) +
  geom_jitter() +
  labs(title = "Distribuição de duração por atividade",
       x = "Atividade",
       y= "Duração")

t <- atv_aluno_duracao %>% 
  ggplot(aes(x = paradigma,
             y = duracao)) +
  geom_boxplot() +
  ggtitle("Boxplot com duração por paradigma", subtitle = waiver()) +
  geom_point()
  #geom_jitter()

ggplotly(t)
```

### Teste estatístico

```{r}
shapiro.test(atv_aluno_duracao$duracao)
kruskal.test(atv_aluno_duracao$duracao, as.factor(atv_aluno_duracao$paradigma))

imperativo <- atv_aluno_duracao %>%
                filter(paradigma %in% c("Imperativo"))
logico <- atv_aluno_duracao %>%
                filter(paradigma %in% c("Lógico"))
funcional <- atv_aluno_duracao %>%
                filter(paradigma %in% c("Funcional"))

wilcox.test(imperativo$duracao, funcional$duracao)
wilcox.test(imperativo$duracao, logico$duracao)
wilcox.test(logico$duracao, funcional$duracao)
```


###  Tempo agrupado por laboratório

```{r}
atv_aluno_duracao %>% 
  ggplot(aes(x = cod_atividade,
             y = duracao,
             color = laboratorio)) +
  geom_jitter() +
  labs(title = "Distribuição de duração por laboratório",
       x = "Atividade",
       y= "Duração")

t <- atv_aluno_duracao %>% 
  ggplot(aes(x = laboratorio,
             y = duracao)) +
  geom_boxplot() +
  ggtitle("Boxplot com duração por laboratório", subtitle = waiver()) +
  geom_point()
  #geom_jitter()

ggplotly(t)



kruskal.test(atv_aluno_duracao$duracao, as.factor(atv_aluno_duracao$laboratorio))

c <- atv_aluno_duracao %>%
                filter(laboratorio %in% c("C"))
haskellba <- atv_aluno_duracao %>%
                filter(laboratorio %in% c("HaskellBasico"))
haskellav <- atv_aluno_duracao %>%
                filter(laboratorio %in% c("HaskellAvancado"))
prologba <- atv_aluno_duracao %>%
                filter(laboratorio %in% c("PrologBasico"))
prologav <- atv_aluno_duracao %>%
                filter(laboratorio %in% c("PrologAvancado"))

wilcox.test(c$duracao, haskellav$duracao)
wilcox.test(c$duracao, haskellba$duracao)
wilcox.test(c$duracao, prologav$duracao)
wilcox.test(c$duracao, prologba$duracao)


wilcox.test(haskellav$duracao, prologav$duracao)
wilcox.test(haskellba$duracao, prologav$duracao)
wilcox.test(prologba$duracao, prologav$duracao)

wilcox.test(haskellav$duracao, prologba$duracao)
wilcox.test(haskellba$duracao, prologba$duracao)

wilcox.test(haskellav$duracao, haskellba$duracao)
```